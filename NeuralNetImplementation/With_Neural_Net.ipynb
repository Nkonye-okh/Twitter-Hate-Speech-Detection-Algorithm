{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "  #Replace all digits with space\n",
    "  text = re.sub(r\"[\\d-]\",'',text)\n",
    "  # Remove Unicode characters\n",
    "  text = re.sub(r'[^\\x00-\\x7F]+', '',text)\n",
    "  #Remove retweets\n",
    "  text = re.sub('user', '', text)\n",
    "  # Remove urls\n",
    "  text = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', text)\n",
    "  text = re.sub(\"[^a-zA-Z]\", ' ',text)\n",
    "  # Remove mentions:\n",
    "  text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "  return text\n",
    "\n",
    "df.tweet = df.tweet.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for  lyft credit i can t use cause ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate   isz that youuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>sikh  temple vandalised in in  calgary   ws...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you   for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0     when a father is dysfunctional and is so se...\n",
       "1          2      0      thanks for  lyft credit i can t use cause ...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0   model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide  society now     motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0                             ate   isz that youuu  \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1     sikh  temple vandalised in in  calgary   ws...\n",
       "31961  31962      0                       thank you   for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD1CAYAAABQtIIDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQXklEQVR4nO3df6hf9X3H8eerSedknc7qVbKbuEjNWFVYiiEL9J9uGTNr/4gFhesfNYxAilhYYX9M+0+3PwL1j1UQpmCxGKWrBttiaGs3iS2lTLS3xdVG67xUq3cJmlXn7B+6JX3vj+/7sm+u39yf8d7U+3zA4Zzv+5zP8X3gyuuezznfm1QVkiS9b7UbkCSdHQwESRJgIEiSmoEgSQIMBElSMxAkSQCsX+0Gluqiiy6qzZs3r3YbkvQb5Uc/+tF/VtXYqH2/sYGwefNmJicnV7sNSfqNkuQXp9vnlJEkCTAQJEnNQJAkAQsIhCS/neTJJP+W5EiSv+/6B5M8muT5Xl8wNObWJFNJnktyzVD96iRP9747kqTr5yR5sOtPJNn8LlyrJGkOC7lDeBv4s6r6Y2ArsCvJDuAW4HBVbQEO92eSXAFMAFcCu4A7k6zrc90F7AO29LKr63uB16vqcuB24LblX5okaTHmDYQa+FV/fH8vBewGDnT9AHBtb+8GHqiqt6vqBWAK2J5kA3BeVT1egz+xet+sMTPnegjYOXP3IElaGQt6hpBkXZKngFeBR6vqCeCSqjoG0OuL+/Bx4OWh4dNdG+/t2fVTxlTVCeAN4MIRfexLMplk8vjx4wu6QEnSwiwoEKrqZFVtBTYy+G3/qjkOH/Wbfc1Rn2vM7D7urqptVbVtbGzk9yokSUu0qC+mVdV/Jfkeg7n/V5JsqKpjPR30ah82DWwaGrYRONr1jSPqw2Omk6wHzgdeW+S1nJU23/Kt1W7hPeXFL3xitVuQ3rMW8pbRWJLf6+1zgT8HfgYcAvb0YXuAh3v7EDDRbw5dxuDh8ZM9rfRmkh39fODGWWNmznUd8Fj5T7lJ0opayB3CBuBAvyn0PuBgVX0zyePAwSR7gZeA6wGq6kiSg8AzwAng5qo62ee6CbgXOBd4pBeAe4D7k0wxuDOYOBMXJ0lauHkDoap+AnxkRP2XwM7TjNkP7B9RnwTe8fyhqt6iA0WStDr8prIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJKABQRCkk1Jvpvk2SRHkvx11/8uyX8keaqXjw+NuTXJVJLnklwzVL86ydO9744k6fo5SR7s+hNJNr8L1ypJmsNC7hBOAH9TVR8GdgA3J7mi991eVVt7+TZA75sArgR2AXcmWdfH3wXsA7b0sqvre4HXq+py4HbgtuVfmiRpMeYNhKo6VlU/7u03gWeB8TmG7AYeqKq3q+oFYArYnmQDcF5VPV5VBdwHXDs05kBvPwTsnLl7kCStjEU9Q+ipnI8AT3TpM0l+kuTLSS7o2jjw8tCw6a6N9/bs+iljquoE8AZw4WJ6kyQtz4IDIckHgK8Bn62q/2Yw/fMhYCtwDPiHmUNHDK856nONmd3DviSTSSaPHz++0NYlSQuwoEBI8n4GYfCVqvo6QFW9UlUnq+rXwJeA7X34NLBpaPhG4GjXN46onzImyXrgfOC12X1U1d1Vta2qto2NjS3sCiVJC7KQt4wC3AM8W1VfHKpvGDrsk8BPe/sQMNFvDl3G4OHxk1V1DHgzyY4+543Aw0Nj9vT2dcBj/ZxBkrRC1i/gmI8CnwKeTvJU1z4H3JBkK4OpnReBTwNU1ZEkB4FnGLyhdHNVnexxNwH3AucCj/QCg8C5P8kUgzuDieVclCRp8eYNhKr6AaPn+L89x5j9wP4R9UngqhH1t4Dr5+tFkvTu8ZvKkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVKbNxCSbEry3STPJjmS5K+7/sEkjyZ5vtcXDI25NclUkueSXDNUvzrJ073vjiTp+jlJHuz6E0k2vwvXKkmaw0LuEE4Af1NVHwZ2ADcnuQK4BThcVVuAw/2Z3jcBXAnsAu5Msq7PdRewD9jSy66u7wVer6rLgduB287AtUmSFmHeQKiqY1X1495+E3gWGAd2Awf6sAPAtb29G3igqt6uqheAKWB7kg3AeVX1eFUVcN+sMTPnegjYOXP3IElaGYt6htBTOR8BngAuqapjMAgN4OI+bBx4eWjYdNfGe3t2/ZQxVXUCeAO4cDG9SZKWZ8GBkOQDwNeAz1bVf8916IhazVGfa8zsHvYlmUwyefz48flaliQtwoICIcn7GYTBV6rq611+paeB6PWrXZ8GNg0N3wgc7frGEfVTxiRZD5wPvDa7j6q6u6q2VdW2sbGxhbQuSVqghbxlFOAe4Nmq+uLQrkPAnt7eAzw8VJ/oN4cuY/Dw+MmeVnozyY4+542zxsyc6zrgsX7OIElaIesXcMxHgU8BTyd5qmufA74AHEyyF3gJuB6gqo4kOQg8w+ANpZur6mSPuwm4FzgXeKQXGATO/UmmGNwZTCzvsiRJizVvIFTVDxg9xw+w8zRj9gP7R9QngatG1N+iA0WStDr8prIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1OYNhCRfTvJqkp8O1f4uyX8keaqXjw/tuzXJVJLnklwzVL86ydO9744k6fo5SR7s+hNJNp/ha5QkLcBC7hDuBXaNqN9eVVt7+TZAkiuACeDKHnNnknV9/F3APmBLLzPn3Au8XlWXA7cDty3xWiRJyzBvIFTV94HXFni+3cADVfV2Vb0ATAHbk2wAzquqx6uqgPuAa4fGHOjth4CdM3cPkqSVs5xnCJ9J8pOeUrqga+PAy0PHTHdtvLdn108ZU1UngDeAC5fRlyRpCZYaCHcBHwK2AseAf+j6qN/sa476XGPeIcm+JJNJJo8fP76ohiVJc1tSIFTVK1V1sqp+DXwJ2N67poFNQ4duBI52feOI+iljkqwHzuc0U1RVdXdVbauqbWNjY0tpXZJ0GksKhH4mMOOTwMwbSIeAiX5z6DIGD4+frKpjwJtJdvTzgRuBh4fG7Ont64DH+jmDJGkFrZ/vgCRfBT4GXJRkGvg88LEkWxlM7bwIfBqgqo4kOQg8A5wAbq6qk32qmxi8sXQu8EgvAPcA9yeZYnBnMHEGrkuStEjzBkJV3TCifM8cx+8H9o+oTwJXjai/BVw/Xx+SpHeX31SWJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIktq8gZDky0leTfLTodoHkzya5PleXzC079YkU0meS3LNUP3qJE/3vjuSpOvnJHmw608k2XyGr1GStAALuUO4F9g1q3YLcLiqtgCH+zNJrgAmgCt7zJ1J1vWYu4B9wJZeZs65F3i9qi4HbgduW+rFSJKWbt5AqKrvA6/NKu8GDvT2AeDaofoDVfV2Vb0ATAHbk2wAzquqx6uqgPtmjZk510PAzpm7B0nSylnqM4RLquoYQK8v7vo48PLQcdNdG+/t2fVTxlTVCeAN4MIl9iVJWqIz/VB51G/2NUd9rjHvPHmyL8lkksnjx48vsUVJ0ihLDYRXehqIXr/a9Wlg09BxG4GjXd84on7KmCTrgfN55xQVAFV1d1Vtq6ptY2NjS2xdkjTKUgPhELCnt/cADw/VJ/rNocsYPDx+sqeV3kyyo58P3DhrzMy5rgMe6+cMkqQVtH6+A5J8FfgYcFGSaeDzwBeAg0n2Ai8B1wNU1ZEkB4FngBPAzVV1sk91E4M3ls4FHukF4B7g/iRTDO4MJs7IlUmSFmXeQKiqG06za+dpjt8P7B9RnwSuGlF/iw4USdLq8ZvKkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVJbViAkeTHJ00meSjLZtQ8meTTJ872+YOj4W5NMJXkuyTVD9av7PFNJ7kiS5fQlSVq8M3GH8KdVtbWqtvXnW4DDVbUFONyfSXIFMAFcCewC7kyyrsfcBewDtvSy6wz0JUlahHdjymg3cKC3DwDXDtUfqKq3q+oFYArYnmQDcF5VPV5VBdw3NEaStEKWGwgF/EuSHyXZ17VLquoYQK8v7vo48PLQ2Omujff27LokaQWtX+b4j1bV0SQXA48m+dkcx456LlBz1N95gkHo7AO49NJLF9urJGkOy7pDqKqjvX4V+AawHXilp4Ho9at9+DSwaWj4RuBo1zeOqI/6791dVduqatvY2NhyWpckzbLkQEjyO0l+d2Yb+Avgp8AhYE8ftgd4uLcPARNJzklyGYOHx0/2tNKbSXb020U3Do2RJK2Q5UwZXQJ8o98QXQ/8U1V9J8kPgYNJ9gIvAdcDVNWRJAeBZ4ATwM1VdbLPdRNwL3Au8EgvkqQVtORAqKqfA388ov5LYOdpxuwH9o+oTwJXLbUXSdLy+U1lSRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpLbcf0JT0m+ozbd8a7VbeE958QufWO0Wls07BEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJOAsCoQku5I8l2QqyS2r3Y8krTVnRSAkWQf8I/CXwBXADUmuWN2uJGltOSsCAdgOTFXVz6vqf4AHgN2r3JMkrSlny5+/HgdeHvo8DfzJ7IOS7AP29cdfJXluBXpbKy4C/nO1m5hPblvtDrQK/Nk8s/7gdDvOlkDIiFq9o1B1N3D3u9/O2pNksqq2rXYf0mz+bK6cs2XKaBrYNPR5I3B0lXqRpDXpbAmEHwJbklyW5LeACeDQKvckSWvKWTFlVFUnknwG+GdgHfDlqjqyym2tNU7F6Wzlz+YKSdU7puolSWvQ2TJlJElaZQaCJAkwECRJ7ax4qKyVleSPGHwTfJzB9z2OAoeq6tlVbUzSqvIOYY1J8rcM/jRIgCcZvPIb4Kv+UUGdzZL81Wr38F7nW0ZrTJJ/B66sqv+dVf8t4EhVbVmdzqS5JXmpqi5d7T7ey5wyWnt+Dfw+8ItZ9Q29T1o1SX5yul3AJSvZy1pkIKw9nwUOJ3me//+DgpcClwOfWa2mpHYJcA3w+qx6gH9d+XbWFgNhjamq7yT5QwZ/cnycwf9o08APq+rkqjYnwTeBD1TVU7N3JPneinezxvgMQZIE+JaRJKkZCJIkwECQJDUDQZIEGAiSpPZ/zWmLdfUQr+0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 512\n",
    "num_samples = len(df)\n",
    "\n",
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize - this time returning Numpy tensors\n",
    "tokens = tokenizer(df['tweet'].tolist(), max_length=seq_len, truncation=True,\n",
    "                   padding='max_length', add_special_tokens=True,\n",
    "                   return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1165,   170, ...,     0,     0,     0],\n",
       "       [  101,  5438,  1111, ...,     0,     0,     0],\n",
       "       [  101, 16516,  1324, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  5578,  1106, ...,     0,     0,     0],\n",
       "       [  101, 27466,  9862, ...,     0,     0,     0],\n",
       "       [  101,  6243,  1128, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets_xids.npy', 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "\n",
    "with open('tweets_xmask.npy', 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 1, 0], dtype=int64), (31962,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = df['label'].values\n",
    "arr, arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((num_samples, arr.max()+1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[np.arange(num_samples),arr] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets_labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets_xids.npy', 'rb') as f:\n",
    "    Xids = np.load(f, allow_pickle=True)\n",
    "with open('tweets_xmask.npy', 'rb') as f:\n",
    "    Xmask = np.load(f, allow_pickle=True)\n",
    "with open('tweets_labels.npy', 'rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 512)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(2,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_funct(ids, mask, labels):\n",
    "    return {'input_ids': ids, 'attention_mask':mask},labels\n",
    "\n",
    "dataset = dataset.map(map_funct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int32, name=None)}, TensorSpec(shape=(2,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(3, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(3, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(3, 2), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "dataset = dataset.shuffle(3000).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and validation set\n",
    "split = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9588"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int((Xids.shape[0] / batch_size) * split)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset.take(size)\n",
    "val_set = dataset.skip(size)\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(3, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(3, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(3, 2), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ReDI_NRW_765\\AppData\\Local\\Temp\\ipykernel_15320\\1719048315.py:1: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.save(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.save(train_set, 'train')\n",
    "tf.data.experimental.save(val_set, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(3, 512), dtype=tf.int32, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(3, 512), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(3, 2), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set.element_spec == train_set.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ReDI_NRW_765\\AppData\\Local\\Temp\\ipykernel_15320\\3519110156.py:1: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.experimental.load('train', element_spec=train_set.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# we can view the model using the summary method\n",
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
    "embeddings = bert.bert(input_ids, attention_mask=mask)[0]  # access final activations with [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bert embeddings into 2 output classes\n",
    "x = tf.keras.layers.LSTM(32, dropout=.3, recurrent_dropout=.3, return_sequences=True)(embeddings)\n",
    "x = tf.keras.layers.LSTM(16, dropout=.4, recurrent_dropout=.4, return_sequences=False)(x)\n",
    "# normalize\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "# output\n",
    "x = tf.keras.layers.Dense(2, activation='relu')(x)\n",
    "y = tf.keras.layers.Dense(2, activation='softmax', name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 512, 32)      102528      ['bert[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 16)           3136        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16)          64          ['lstm_1[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            34          ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 2)            6           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,416,040\n",
      "Trainable params: 105,736\n",
      "Non-trainable params: 108,310,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "# (optional) freeze bert layer\n",
    "model.layers[2].trainable = False\n",
    "\n",
    "# print out model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ReDI_NRW_765\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=1e-4, decay=1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(3, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(3, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(3, 2), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(3, 512), dtype=tf.int32, name=None),\n",
    "                 'attention_mask': tf.TensorSpec(shape=(3, 512), dtype=tf.int32, name=None)},\n",
    "                tf.TensorSpec(shape=(3, 2), dtype=tf.float64, name=None))\n",
    "                \n",
    "# load the training and validation sets\n",
    "train_ds = tf.data.experimental.load('train', element_spec=element_spec)\n",
    "val_ds = tf.data.experimental.load('val', element_spec=element_spec)\n",
    "\n",
    "# view the input format\n",
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     train_ds,\n\u001b[0;32m      3\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentiment_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('sentiment_model')\n",
    "\n",
    "# view model architecture to confirm we have save and loaded correctly\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def prep_data(text):\n",
    "    tokens = tokenizer.encode_plus(text, max_length=512,\n",
    "                                   truncation=True, padding='max_length',\n",
    "                                   add_special_tokens=True, return_token_type_ids=False,\n",
    "                                   return_tensors='tf')\n",
    "    # tokenizer returns int32 tensors, we need to return float64, so we use tf.cast\n",
    "    return {'input_ids': tokens['input_ids'],\n",
    "            'attention_mask': tokens['attention_mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# so we can see full phrase\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "dfa = pd.read_csv('test.csv')\n",
    "dfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "  #Replace all digits with space\n",
    "  text = re.sub(r\"[\\d-]\",'',text)\n",
    "  # Remove Unicode characters\n",
    "  text = re.sub(r'[^\\x00-\\x7F]+', '',text)\n",
    "  #Remove retweets\n",
    "  text = re.sub('user', '', text)\n",
    "  # Remove urls\n",
    "  text = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', text)\n",
    "  text = re.sub(\"[^a-zA-Z]\", ' ',text)\n",
    "  # Remove mentions:\n",
    "  text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "  return text\n",
    "\n",
    "dfa.tweet = dfa.tweet.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['Label'] = None\n",
    "\n",
    "for i, row in dfa.iterrows():\n",
    "    # get token tensors\n",
    "    tokens = prep_data(row['tweet'])\n",
    "    # get probabilities\n",
    "    probs = model.predict(tokens)\n",
    "    # find argmax for winning class\n",
    "    pred = np.argmax(probs)\n",
    "    # add to dataframe\n",
    "    dfa.at[i, 'Label'] = pred\n",
    "\n",
    "dfa.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf68b5f3d8f23fabb64fa988f1c08fc25a98e529a37082d4f0f1b429c1758919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
